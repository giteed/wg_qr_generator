# **AI Assistant Directory**

Данный каталог содержит все необходимые данные, настройки и скрипты для работы AI-ассистента. Ассистент предназначен для анализа состояния сервера, работы с WireGuard, обработки входных данных и генерации выводов с использованием модели LLM.

## **Структура каталогов**

### **1. `/ai_assistant/inputs/`**
**Описание**: Хранение входных данных для анализа.  
- **`inputs.md`**: Документация по формату и назначению входных данных.
- **Примеры файлов**:
  - `wg_status.json`: Результаты команды `wg show`.
  - `wg0_config.json`: Разобранный файл `/etc/wireguard/wg0.conf`.
  - `params_config.json`: Разобранный файл `/etc/wireguard/params`.

---

### **2. `/ai_assistant/prompts/`**
**Описание**: Шаблоны промптов для взаимодействия с моделью LLM.  
- **`prompts.md`**: Документация о формате и назначении промптов.  
- **Примеры файлов**:
  - `default_prompt.txt`: Базовый промпт для анализа состояния системы.
  - `analysis_prompt.txt`: Специализированный промпт для анализа WireGuard.

---

### **3. `/ai_assistant/models/`**
**Описание**: Настройки, примеры и вспомогательные данные для модели LLM.  
- **`models.md`**: Документация по конфигурации и настройке моделей.  
- **Примеры файлов**:
  - `config.json`: Настройки подключения к LLM (адрес API, модель, параметры).
  - `examples/`: Примеры входных данных и их обработки моделью.

---

### **4. `/ai_assistant/outputs/`**
**Описание**: Результаты работы ассистента.  
- **`outputs.md`**: Документация по структуре выходных данных.  
- **Примеры файлов**:
  - `insights.json`: Аналитические данные, полученные от модели.
  - `logs/`: Директория с логами работы:
    - `error.log`: Логи ошибок.
    - `activity.log`: Логи активности.

---

### **5. `/ai_assistant/scripts/`**
**Описание**: Вспомогательные скрипты для обработки данных и взаимодействия с моделью LLM.  
- **`scripts.md`**: Документация по использованию скриптов.  
- **Примеры файлов**:
  - `preprocess.py`: Скрипт для предварительной обработки данных.
  - `query_model.py`: Скрипт для взаимодействия с LLM.

---

### **6. `/ai_assistant/chats/`**
**Описание**: История чатов между ассистентом и администратором.  
- **`chats.md`**: Документация по хранению и структуре чатов.  
- **Примеры файлов**:
  - `chat_2024-12-21.json`: Лог чата с администратором за конкретную дату.

---

## **Использование**

1. **Сбор данных**:
   - Поместите входные данные в директорию `/inputs/` в формате JSON или текстовых файлов.

2. **Шаблоны промптов**:
   - Отредактируйте или добавьте новые промпты в `/prompts/` для настройки взаимодействия с LLM.

3. **Запуск анализа**:
   - Используйте скрипты из `/scripts/` для обработки данных и отправки запросов в модель.

4. **Результаты**:
   - Готовые выводы и логи работы ассистента будут сохранены в `/outputs/`.

5. **Чаты**:
   - История взаимодействий ассистента с администратором сохраняется в `/chats/`.

---

## **Примечания**
- Для корректной работы ассистента убедитесь, что у него есть доступ к необходимым данным и файлам конфигурации.
- Все настройки взаимодействия с моделью находятся в `/models/config.json`.

